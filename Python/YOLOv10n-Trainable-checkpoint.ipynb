{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804616df-31b4-431c-b7db-a500b9719a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import Video\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# DISCLAIMER:\n",
    "# This script is best used when training higher epoch(s) (recommended)\n",
    "# That way you have less issues with resume_training function\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"   # avoids MKL crashes on some Windows setups\n",
    "torch.set_num_threads(1)                      # keeps CPU thread count sane for Jupyter\n",
    "\n",
    "# set to True if you want to resume training from a previous model\n",
    "resume_training = False\n",
    "# path to csv metrics\n",
    "csv_path = \"PATH/TO/results.csv\"\n",
    "\n",
    "# path to your previously trained model weights for 'best' and 'last'\n",
    "previous_model_path_best = \"PATH/TO/best.pt\"\n",
    "previous_model_path_last = \"PATH/TO/last.pt\"\n",
    "\n",
    "# new dataset path for retraining (you can keep same one or point to new)\n",
    "# Hard to avoid conflicts if you change data sets when resume_training = True\n",
    "dataset_path = \"PATH/TO/data.yaml\"\n",
    "\n",
    "# total desired epochs overall\n",
    "target_epochs = 50\n",
    "\n",
    "\n",
    "if resume_training:\n",
    "    print(\"Resuming training from previous model...\")\n",
    "    model = YOLO(previous_model_path_best)\n",
    "    \n",
    "    results = model.train(\n",
    "        data=dataset_path,       # data set path\n",
    "        tracker=\"bytetrack.yaml\",   # Options: 'bytetrack.yaml', 'botsort.yaml', 'ocsort.yaml'\n",
    "        epochs=target_epochs,              # increase for better accuracy\n",
    "        imgsz=640,              # image size\n",
    "        batch=4,                # adjust depending on VRAM\n",
    "        plots=False,            # no matplotlib plotting during train\n",
    "        amp=False,             # turn off mixed precision if your driver/CUDA combo is touchy\n",
    "        device=\"cuda:0\",        # Use GPU acceleration if available (default True). Set False for CPU-only.\n",
    "        workers=0,              # disables multiprocessing\n",
    "        cache=False,            # disable pre-caching (keeps memory stable)\n",
    "        deterministic=True,     # prevents race conditions\n",
    "        resume=False,            # continue from previous checkpoints\n",
    "        #lr0=0.0005,                # lower learning rate to prevent NaN explosion\n",
    "        exist_ok=True,\n",
    "        name=\"drone_detector\",  # output folder name\n",
    "        project=\"D:/Anaconda-Projects/yolo_env/runs/train\",\n",
    "    )\n",
    "else:\n",
    "    print(\"Starting new training from yolov8s.pt...\")\n",
    "    # Load pretrained YOLOv8s model\n",
    "    model = YOLO(previous_model_path_best)\n",
    "    results = model.train(\n",
    "        data=dataset_path,\n",
    "        # Tracker configuration YAML file (controls which algorithm to use)\n",
    "        tracker=\"bytetrack.yaml\",   # Options: 'bytetrack.yaml', 'botsort.yaml', 'ocsort.yaml'\n",
    "        epochs=target_epochs,              # increase for better accuracy\n",
    "        imgsz=640,              # image size\n",
    "        batch=6,                # adjust depending on VRAM\n",
    "        device=\"cuda:0\",        # Use GPU acceleration if available (default True). Set False for CPU-only.\n",
    "        exist_ok=True,\n",
    "        workers=0,              # critical fix: disables multiprocessing\n",
    "        cache=False,            # disable pre-caching (keeps memory stable)\n",
    "        resume=False,            # continue from previous checkpoints\n",
    "        amp=False,             # turn off mixed precision if your driver/CUDA combo is touchy\n",
    "        deterministic=True,     # prevents race conditions\n",
    "        name=\"drone_detector_50epoch\",  # output folder name\n",
    "        project=\"D:/Anaconda-Projects/yolo_env/runs/train\",\n",
    "    )\n",
    "\n",
    "# # Optional: print metrics\n",
    "# metrics = results.results_dict\n",
    "# print(\"\\nTraining Results:\")\n",
    "# print(f\"mAP50: {metrics.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "# print(f\"Precision: {metrics.get('metrics/precision(B)', 'N/A')}\")\n",
    "# print(f\"Recall: {metrics.get('metrics/recall(B)', 'N/A')}\")\n",
    "\n",
    "    #Run YOLO inference\n",
    "    #results = model.predict(\n",
    "            # Tracker configuration YAML file (controls which algorithm to use).\n",
    "            # Options: 'bytetrack.yaml', 'botsort.yaml', 'ocsort.yaml'\n",
    "            ##tracker=\"bytetrack.yaml\",   # or 'botsort.yaml'\n",
    "            # Path to the video, image folder, webcam index (0), or stream URL.\n",
    "            # Examples: \"video.mp4\", 0, \"rtsp://...\", \"folder_of_images/\"\n",
    "            #source=frame,\n",
    "            # Verbosity control: print logs (True) or suppress (False).\n",
    "            #verbose=False,\n",
    "            # Whether to display the results in a pop-up OpenCV window.\n",
    "            #show=True,                       # shows frames in a pop-up window\n",
    "            # When True, saves to: runs/track/{name}/\n",
    "            #save=False,                       # saves output under runs/detect/\n",
    "            # Minimum confidence threshold for detection (0.0–1.0).\n",
    "            # Detections below this confidence are ignored.\n",
    "            #conf=0.25,                        # confidence threshold\n",
    "            # Set image size for inference. Smaller = faster but less accurate.\n",
    "            # Typical values: 640, 720, 1080\n",
    "            #imgsz=640,                       #smaller frame size\n",
    "            # IoU (Intersection over Union) threshold for non-max suppression (0.0–1.0).\n",
    "            # Higher = fewer overlapping boxes, lower = more.\n",
    "            #iou=0.7,\n",
    "            # Directory where outputs (video, logs, etc.) are stored.\n",
    "            #project=\"D:/Anaconda-Projects/YOLO-Outputs\",\n",
    "            # Name of the subfolder under 'project' where this run’s files go.\n",
    "            # Combined path example: D:/Anaconda-Projects/YOLO-Outputs/drone_tracking/\n",
    "            #name=\"drone_tracking\",\n",
    "            # If True, overwrites existing folders with the same name instead of creating 'drone_tracking2', etc.\n",
    "            #exist_ok=False,\n",
    "            # Use GPU acceleration if available (default True). Set False for CPU-only.\n",
    "            #device=cuda:0,  # examples: 'cpu', 'cuda:0', 'cuda:1'\n",
    "            # Whether to visualize model predictions inline (useful in notebooks).\n",
    "            # Usually disabled when 'show=True'.\n",
    "            #visualize=False,\n",
    "            # Whether to return tracking results as a generator instead of accumulating all in memory.\n",
    "            # Prevents out-of-memory errors for long videos or streams.\n",
    "            #stream=False,\n",
    "            # Maximum number of detections per image.\n",
    "            #max_det=300,\n",
    "            # Classes to detect (list of class IDs). e.g., [0] for 'person', [2, 3, 5] for specific objects.\n",
    "            # None = detect all classes.\n",
    "            #classes=None,\n",
    "            # Enable or disable saving of cropped detections.\n",
    "            #save_crop=False,\n",
    "            # Save text labels (bounding box coordinates and class IDs) to *.txt files.\n",
    "            #save_txt=False,\n",
    "            # Line thickness for bounding boxes in the display.\n",
    "            #line_width=2,\n",
    "            # Whether to automatically open the output folder after completion.\n",
    "            #show_labels=False,\n",
    "            # Control tracker-specific behavior (inside the YAML config).\n",
    "            # Examples: tracking buffer size, re-ID thresholds, frame rate smoothing, etc.\n",
    "        #)\n",
    "\n",
    "\n",
    "# Print detection summary\n",
    "print(\"Training finished!!!\")\n",
    "print(\"Training finished!\")\n",
    "print(f\"Model saved under: {model.trainer.save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO Env",
   "language": "python",
   "name": "yolo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
